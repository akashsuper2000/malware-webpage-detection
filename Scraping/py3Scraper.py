from bs4 import BeautifulSoup
from collections import Counter
import requests
import re
import csv

def fun(params):
    url = params['url']
    if len(url) == 0:
        return
    if url[-1] !='/':
        url+='/'
           
    domainNameBackCheck = ["google","facebook","yahoo","instagram","youtube","paypal","amazon"]
    permuteListDict =[] #Check dnstwist

    domainExtractionRegex = "/([a-z0-9|-]+\.)*[a-z0-9|-]+\.[a-z]+/"
    #url = str(input("Enter an URL to extract features:"))
    #url = str(sys.argv[1])
    lister = re.search(domainExtractionRegex, url)
    values = {}
    dig = 0
    esc = 0

    for i in range(len(url)):
        try:
            l = int(url[i])
            dig+=1
        except:
            continue

    #values["url"] = url
    values["digitsInURL"] = dig
    values["lenOfURL"] = len(url)
    if lister!=None:
        values["domainsList"] = list(lister.group().split('.'))
    else:
        values["domainsList"] = list([''])
    try:
        res = requests.get(url,timeout=5)
        if res.status_code != 200:
            #print(url,res.status_code)
            return
    except Exception as err:
        print(err)
        return
    page_source = res.text
    filtered = page_source
    values['esc'] = page_source.count("\n") + page_source.count("\v") + page_source.count("\t")
    values['ln'] = len(page_source)
    words = [word for word in filtered.split() if word]
    if len(words) !=0:
        values['avglen'] = sum(map(len,words))/len(words)
    else:
        values['avglen'] =  0
    values['wordcount'] = len(words)
    values['distCount'] = len(Counter(filtered.split()))
    values['linkcount'] = filtered.count("link rel")
    values['hrefcount'] = filtered.count("href")
    values['evalCount'] = filtered.count("eval()")
    values['unescapeCount'] = filtered.count("unescape()")
    values['escapeCount'] = filtered.count("escape()")
    values['searchCount'] = filtered.count("search()")
    values['execCount'] = filtered.count("exec()")
    values['linkCount'] = filtered.count("link()")
    values['activeXCount'] = filtered.count("ActiveX")
    for key in params.keys():
        values[key] = params[key]
    with open("output.csv","a+",newline='') as csvfile:
        fieldnames = ['url','digitsInURL','lenOfURL','domainsList','esc','ln','avglen','wordcount','distCount','linkcount','hrefcount','evalCount','unescapeCount','escapeCount','searchCount','execCount','linkCount','activeXCount','phish_id','phish_detail_url','submission_time','verified','verification_time','online','target']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writerow(values)

